{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e2a5c82",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Missing values per column:\n",
      "Flow Bytes/s    4\n",
      "dtype: int64\n",
      "\n",
      "Rows with missing values and count of missing values:\n",
      "6796      1\n",
      "14739     1\n",
      "15047     1\n",
      "209728    1\n",
      "dtype: int64\n",
      "\n",
      "Rows with missing values:\n",
      "                                          Flow ID      Source IP  \\\n",
      "6796       192.168.10.16-198.54.12.145-36812-80-6  198.54.12.145   \n",
      "14739   192.168.10.25-192.168.10.50-53581-37575-6  192.168.10.50   \n",
      "15047          192.168.10.17-1.1.70.73-48283-80-6  192.168.10.17   \n",
      "209728  192.168.10.17-192.168.10.50-39026-18467-6  192.168.10.17   \n",
      "\n",
      "         Source Port  Destination IP   Destination Port   Protocol  \\\n",
      "6796              80   192.168.10.16              36812          6   \n",
      "14739          37575   192.168.10.25              53581          6   \n",
      "15047          48283       1.1.70.73                 80          6   \n",
      "209728         39026   192.168.10.50              18467          6   \n",
      "\n",
      "            Timestamp   Flow Duration   Total Fwd Packets  \\\n",
      "6796    7/7/2017 3:35               0                   2   \n",
      "14739   7/7/2017 3:46               0                   1   \n",
      "15047   7/7/2017 3:48               0                   2   \n",
      "209728  7/7/2017 4:34               0                   2   \n",
      "\n",
      "         Total Backward Packets  ...   min_seg_size_forward  Active Mean  \\\n",
      "6796                          0  ...                     32          0.0   \n",
      "14739                         1  ...                     44          0.0   \n",
      "15047                         0  ...                     32          0.0   \n",
      "209728                        0  ...                     32          0.0   \n",
      "\n",
      "         Active Std   Active Max   Active Min  Idle Mean   Idle Std  \\\n",
      "6796            0.0            0            0        0.0        0.0   \n",
      "14739           0.0            0            0        0.0        0.0   \n",
      "15047           0.0            0            0        0.0        0.0   \n",
      "209728          0.0            0            0        0.0        0.0   \n",
      "\n",
      "         Idle Max   Idle Min   Label  \n",
      "6796            0          0  BENIGN  \n",
      "14739           0          0  BENIGN  \n",
      "15047           0          0  BENIGN  \n",
      "209728          0          0  BENIGN  \n",
      "\n",
      "[4 rows x 85 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the dataset (replace with the correct path if needed)\n",
    "csv_file_path = '/scratch1/e20-fyp-xai-anomaly-detection/CICDataset/Generated-Labelled-Flow/TrafficLabelling /Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv'\n",
    "print(os.path.exists(csv_file_path))  # Should print True if the file exists\n",
    "\n",
    "dataset = pd.read_csv(csv_file_path, encoding='utf-8')  # Replace with your actual file path\n",
    "\n",
    "\n",
    "# Check for missing values in the entire dataset\n",
    "missing_values = dataset.isnull().sum()\n",
    "\n",
    "# Display columns with missing values and the number of missing values in each column\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# To get the rows with missing values\n",
    "rows_with_missing_values = dataset[dataset.isnull().any(axis=1)]\n",
    "\n",
    "# Display the number of missing values per row\n",
    "rows_with_missing_count = rows_with_missing_values.isnull().sum(axis=1)\n",
    "\n",
    "# Print the rows with missing values and how many missing in each row\n",
    "print(\"\\nRows with missing values and count of missing values:\")\n",
    "print(rows_with_missing_count)\n",
    "\n",
    "# Optionally, display rows with missing values for further inspection\n",
    "print(\"\\nRows with missing values:\")\n",
    "print(rows_with_missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db4264d0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing file: Friday-WorkingHours-Morning.pcap_ISCX.csv\n",
      "Total number of rows: 191033\n",
      "Rows with missing values: 28\n",
      "\n",
      "Analyzing file: Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\n",
      "Total number of rows: 225745\n",
      "Rows with missing values: 4\n",
      "\n",
      "Analyzing file: Wednesday-workingHours.pcap_ISCX.csv\n",
      "Total number of rows: 692703\n",
      "Rows with missing values: 1008\n",
      "\n",
      "Analyzing file: Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3000794/4127186603.py:20: DtypeWarning: Columns (0,1,3,6,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dataset = pd.read_csv(csv_file_path, encoding='ISO-8859-1')  # Use 'ISO-8859-1' or 'utf-8' as needed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows: 458968\n",
      "Rows with missing values: 288622\n",
      "\n",
      "Analyzing file: Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\n",
      "Total number of rows: 286467\n",
      "Rows with missing values: 15\n",
      "\n",
      "Analyzing file: Monday-WorkingHours.pcap_ISCX.csv\n",
      "Total number of rows: 529918\n",
      "Rows with missing values: 64\n",
      "\n",
      "Analyzing file: Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\n",
      "Total number of rows: 288602\n",
      "Rows with missing values: 18\n",
      "\n",
      "Analyzing file: Tuesday-WorkingHours.pcap_ISCX.csv\n",
      "Total number of rows: 445909\n",
      "Rows with missing values: 201\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the directory containing CSV files\n",
    "csv_directory = '/scratch1/e20-fyp-xai-anomaly-detection/CICDataset/Generated-Labelled-Flow/TrafficLabelling '\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in os.listdir(csv_directory):\n",
    "    # Check if the file is a CSV\n",
    "    if filename.endswith('.csv'):\n",
    "        # Construct the full file path\n",
    "        csv_file_path = os.path.join(csv_directory, filename)\n",
    "        \n",
    "        # Check if the file exists\n",
    "        if os.path.exists(csv_file_path):\n",
    "            print(f\"\\nAnalyzing file: {filename}\")\n",
    "            \n",
    "            try:\n",
    "                # Load the dataset with a fallback encoding\n",
    "                dataset = pd.read_csv(csv_file_path, encoding='ISO-8859-1')  # Use 'ISO-8859-1' or 'utf-8' as needed\n",
    "                \n",
    "                # Check for missing values in the entire dataset\n",
    "                missing_values = dataset.isnull().sum()\n",
    "                \n",
    "                # Count total rows and rows with missing values\n",
    "                total_rows = len(dataset)\n",
    "                rows_with_missing_values = dataset[dataset.isnull().any(axis=1)]\n",
    "                rows_with_missing_count = len(rows_with_missing_values)\n",
    "                \n",
    "                # Display file name, total rows, and number of rows with missing values\n",
    "                print(f\"Total number of rows: {total_rows}\")\n",
    "                print(f\"Rows with missing values: {rows_with_missing_count}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file {filename}: {e}\")\n",
    "                \n",
    "        else:\n",
    "            print(f\"File not found: {csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e7319f0-b875-4324-b121-42762814cfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File '/scratch1/e20-fyp-xai-anomaly-detection/CICDataset/Generated-Labelled-Flow/TrafficLabelling /Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv' loaded successfully.\n",
      "\n",
      "\n",
      "Missing values per column:\n",
      "                 Missing Values  Missing Percentage\n",
      "Flow Bytes/s             288622           62.884994\n",
      " Source IP               288602           62.880637\n",
      " Source Port             288602           62.880637\n",
      " Destination IP          288602           62.880637\n",
      "Flow ID                  288602           62.880637\n",
      "...                         ...                 ...\n",
      "Idle Mean                288602           62.880637\n",
      " Idle Std                288602           62.880637\n",
      " Idle Max                288602           62.880637\n",
      " Idle Min                288602           62.880637\n",
      " Label                   288602           62.880637\n",
      "\n",
      "[85 rows x 2 columns]\n",
      "\n",
      "Number of rows with missing values: 288622\n",
      "\n",
      "No issues with reading specific columns.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Path to the Thursday dataset\n",
    "thursday_file_path = '/scratch1/e20-fyp-xai-anomaly-detection/CICDataset/Generated-Labelled-Flow/TrafficLabelling /Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv'\n",
    "\n",
    "# Try to load the dataset with proper error handling\n",
    "try:\n",
    "    # Attempt to read the dataset with encoding that handles issues\n",
    "    dataset = pd.read_csv(thursday_file_path, encoding='ISO-8859-1', low_memory=False)\n",
    "    print(f\"File '{thursday_file_path}' loaded successfully.\\n\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading file {thursday_file_path}: {e}\")\n",
    "    dataset = None\n",
    "\n",
    "# If dataset loaded successfully, proceed to analyze missing values\n",
    "if dataset is not None:\n",
    "    # Check for missing values per column\n",
    "    missing_values = dataset.isnull().sum()\n",
    "    \n",
    "    # Get the total number of rows\n",
    "    total_rows = len(dataset)\n",
    "    \n",
    "    # Display missing values and the percentage of missing values\n",
    "    print(\"\\nMissing values per column:\")\n",
    "    missing_percentage = (missing_values / total_rows) * 100\n",
    "    missing_info = pd.DataFrame({'Missing Values': missing_values, 'Missing Percentage': missing_percentage})\n",
    "    \n",
    "    # Print columns with missing values\n",
    "    print(missing_info[missing_info['Missing Values'] > 0].sort_values(by='Missing Values', ascending=False))\n",
    "    \n",
    "    # Optional: Check rows with the most missing values\n",
    "    rows_with_missing_values = dataset[dataset.isnull().any(axis=1)]\n",
    "    print(f\"\\nNumber of rows with missing values: {len(rows_with_missing_values)}\")\n",
    "\n",
    "    # Check specific columns that could cause reading problems due to encoding or type issues\n",
    "    problematic_columns = []\n",
    "    for column in dataset.columns:\n",
    "        try:\n",
    "            dataset[column].apply(str)  # Try to convert the column to string\n",
    "        except Exception as e:\n",
    "            problematic_columns.append((column, str(e)))\n",
    "    \n",
    "    # Print columns with errors\n",
    "    if problematic_columns:\n",
    "        print(\"\\nColumns with errors during reading:\")\n",
    "        for col, error in problematic_columns:\n",
    "            print(f\"Column: {col}, Error: {error}\")\n",
    "    else:\n",
    "        print(\"\\nNo issues with reading specific columns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc299998-057a-4517-b371-cbe031f42afc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
